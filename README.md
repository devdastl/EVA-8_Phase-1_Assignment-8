# EVA-8_Phase-1_Assignment-8

This is the assignment of 8th session in Phase-1 of EVA-8 from TSAI

## Introduction

### Objective
Objective of this assignment is to train custom resnet model architecture written [here](https://github.com/devdastl/eva8_source/blob/main/models/custom_resnet.py) on [CIFAR10 Dataset](http://yann.lecun.com/exdb/mnist/) and should adhare to following conditions:
1. All major code should in another auxelary repository which will be cloned in this notebook. [link to the repo](https://github.com/devdastl/eva8_source)
2. Need to train the model for 24 epochs using One Cycle Policy, such that:
    - Total Epochs = 24 
    - Max at Epoch = 5
    - LRMIN = FIND
    - LRMAX = FIND
    - NO Annihilation
4. Model should achieve target test accuracy of `90%`.
6. Generate loss-accuracy curve for the trained model.
7. Plot misclassified images, also generate gradcam for misclassified images.

### Getting started
It is very easy to get started with this assignment, just follow below mentioned steps:
1. Open assignment 8 notebook in google colab.
2. Run first cell to clone auxelary repo into the current runtime of colab. Please note that this repo has been upgraded to support modulerised training loop.
4. Note that deleting runtime can reset and delete cloned repository.

## About One Cycle Policy
One Cycle Learning Rate (LR) is a technique used in deep learning models to optimize the learning process. PyTorch is a popular open-source machine learning library that supports this technique. In One Cycle LR, the learning rate is increased linearly until a maximum value is reached and then decreased back to its initial value. This allows the model to quickly converge to a good solution in the first few epochs, followed by slower fine-tuning of the model in later epochs. PyTorch provides a built-in implementation of One Cycle LR in its torch.optim.lr_scheduler module, which can be easily integrated into a training script. Using One Cycle LR in PyTorch can lead to improved training efficiency and faster convergence of the model.
<br>
To get the best Learning rate to for OCP we use torch_lr_finder python package. This package run multiple training pass over multiple LR and give the best LR for our initilized weights of the model.
Using One Cycle LR can be very useful to converge large model faster and converging model faster is good for upcoming assignments! Below is an image showing output graph of LRFinder() and graph of LR generated by OCR.
Graph from LRFinder()                     | Graph of LR from OCR
:---------------------------------------------------:|:--------------------------------------------------:
![Alt text](report/lrf_8.JPG?raw=true "")  | ![Alt text](report/ocp_8.JPG?raw=true "")


## Data representation
In this assignment I am using [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) with this dataset I am applying following augmentation on the top:
1. `RandomCrop` - Cropping 32x32 patches from the input image after giving a padding of 4.
1. `HorizontalFlip` - Fliping the image along horizontal axis.
3. `CoarseDropOut` - Overlay a rectangle patch(half the size of original image) on a image randomly. (simulate object hindarence)
6. `Normalize` - Normalize image i.e. zero centring (zero mean) and scaling (one std)

Below is the graph representing the input training dataset after appling all augmentations c .
![Alt text](report/data_6.JPG?raw=true "model architecture")

## Model representation
As mentioned, in this assignment we are training restNET18 architecture which has 18 convolution layers. You can find the model architecture defination in [auxlary repo](https://github.com/devdastl/eva8_source/blob/main/models/resnet.py).

Below is a snippet of model architecture summary:
```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 32, 32]           1,728
       BatchNorm2d-2           [-1, 64, 32, 32]             128
              ReLU-3           [-1, 64, 32, 32]               0
            Conv2d-4          [-1, 128, 32, 32]          73,728
         MaxPool2d-5          [-1, 128, 16, 16]               0
       BatchNorm2d-6          [-1, 128, 16, 16]             256
              ReLU-7          [-1, 128, 16, 16]               0
           Dropout-8          [-1, 128, 16, 16]               0
            Conv2d-9          [-1, 128, 16, 16]         147,456
      BatchNorm2d-10          [-1, 128, 16, 16]             256
             ReLU-11          [-1, 128, 16, 16]               0
          Dropout-12          [-1, 128, 16, 16]               0
           Conv2d-13          [-1, 128, 16, 16]         147,456
      BatchNorm2d-14          [-1, 128, 16, 16]             256
             ReLU-15          [-1, 128, 16, 16]               0
          Dropout-16          [-1, 128, 16, 16]               0
         ResBlock-17          [-1, 128, 16, 16]               0
           Conv2d-18          [-1, 256, 16, 16]         294,912
        MaxPool2d-19            [-1, 256, 8, 8]               0
      BatchNorm2d-20            [-1, 256, 8, 8]             512
             ReLU-21            [-1, 256, 8, 8]               0
          Dropout-22            [-1, 256, 8, 8]               0
           Conv2d-23            [-1, 512, 8, 8]       1,179,648
        MaxPool2d-24            [-1, 512, 4, 4]               0
      BatchNorm2d-25            [-1, 512, 4, 4]           1,024
             ReLU-26            [-1, 512, 4, 4]               0
          Dropout-27            [-1, 512, 4, 4]               0
           Conv2d-28            [-1, 512, 4, 4]       2,359,296
      BatchNorm2d-29            [-1, 512, 4, 4]           1,024
             ReLU-30            [-1, 512, 4, 4]               0
          Dropout-31            [-1, 512, 4, 4]               0
           Conv2d-32            [-1, 512, 4, 4]       2,359,296
      BatchNorm2d-33            [-1, 512, 4, 4]           1,024
             ReLU-34            [-1, 512, 4, 4]               0
          Dropout-35            [-1, 512, 4, 4]               0
         ResBlock-36            [-1, 512, 4, 4]               0
        MaxPool2d-37            [-1, 512, 1, 1]               0
           Linear-38                   [-1, 10]           5,120
================================================================
Total params: 6,573,120
Trainable params: 6,573,120
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.82
Params size (MB): 25.07
Estimated Total Size (MB): 32.90
----------------------------------------------------------------
```
## Training log
Below are the last five epoch training logs for the custom resnet model which has been trained for 24 epoch using One Cycle Policy.
```
EPOCH: 19
Loss=0.3342881500720978 Batch_id=97 Accuracy=86.60: 100%|██████████| 98/98 [00:26<00:00,  3.69it/s]
Test set: Average loss: 0.0007, Accuracy: 8787/10000 (87.87%)

EPOCH: 20
Loss=0.38533949851989746 Batch_id=97 Accuracy=87.53: 100%|██████████| 98/98 [00:27<00:00,  3.62it/s]
Test set: Average loss: 0.0006, Accuracy: 8914/10000 (89.14%)

EPOCH: 21
Loss=0.31344231963157654 Batch_id=97 Accuracy=87.96: 100%|██████████| 98/98 [00:26<00:00,  3.64it/s]
Test set: Average loss: 0.0006, Accuracy: 8923/10000 (89.23%)

EPOCH: 22
Loss=0.3869306445121765 Batch_id=97 Accuracy=88.57: 100%|██████████| 98/98 [00:26<00:00,  3.72it/s]
Test set: Average loss: 0.0006, Accuracy: 8993/10000 (89.93%)

EPOCH: 23
Loss=0.3095790147781372 Batch_id=97 Accuracy=89.23: 100%|██████████| 98/98 [00:26<00:00,  3.76it/s]
Test set: Average loss: 0.0006, Accuracy: 9026/10000 (90.26%)

EPOCH: 24
Loss=0.2835022509098053 Batch_id=97 Accuracy=89.74: 100%|██████████| 98/98 [00:26<00:00,  3.72it/s]
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24
generating mis-classified images for epoch 24

Test set: Average loss: 0.0005, Accuracy: 9063/10000 (90.63%)
```
## Results
As a result, we will look into generated graphs, mis-classified images and GradCAM of those images.

#### Accuracy-Loss graph
Below is the image showing Accuracy-loss curve for validation dataset.
Accuracy-Loss graph for training                     | Accuracy-Loss graph for validation
:---------------------------------------------------:|:--------------------------------------------------:
![Alt text](report/graph_train_8.png?raw=true "")  | ![Alt text](report/graph_eval_8.png?raw=true "")

#### Mis-classified images
Below is the plot of mis-classified images while validating on 20th epoch.
![Alt text](report/misclassified_8.png?raw=true "")


#### GradCAM of mis-classified images
Below are GradCAM images for 10 mis-classified images. We have captured GradCAM in two different layers
![Alt text](report/misclassified_grad_8.png?raw=true "")
